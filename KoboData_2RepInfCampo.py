# -*- coding: utf-8 -*-
"""KoboCollectData.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g6fYkkyupbeH1hgmXrSzUvRNv-GTVKez
"""

import os
import json
import requests
import pandas as pd
from google.oauth2.service_account import Credentials
import gspread

# === CONFIGURACIÓN ===
KOBO_URL = "https://kf.kobotoolbox.org/assets/axWwJY5A9AeyzcJPtjACaf/submissions/?format=json"
OUTPUT_FOLDER = "output"
OUTPUT_FILE = os.path.join(OUTPUT_FOLDER, "2_ReporteInfCampo.xlsx")
CREDENTIALS_FILE = "credentials.json"
SHEET_ID = "1uhpIYhuFhfYJlHuJKq1VDsj9jFPXS4iW2qxdyPL4aiA"  # <-- Reemplázalo por tu ID real de Google Sheets


# === FUNCIONES ===
def download_kobo_data(url):
    print(f"📥 Descargando: {url}")
    response = requests.get(url)
    response.raise_for_status()
    data = response.json()
    return data.get("results", [])


def split_nested_data(df, parent_name="Main"):
    """
    Detecta columnas con listas o diccionarios y genera sub-hojas.
    Retorna el df plano y un dict de sub_dfs {nombre: DataFrame}.
    """
    sub_dfs = {}
    for col in df.columns:
        if df[col].apply(lambda x: isinstance(x, (list, dict))).any():
            rows = []
            for idx, val in df[col].items():
                if isinstance(val, list):
                    for i, v in enumerate(val):
                        rows.append({"parent_index": idx, "item_index": i, **({"value": v} if not isinstance(v, dict) else v)})
                elif isinstance(val, dict):
                    flat = {"parent_index": idx}
                    flat.update(val)
                    rows.append(flat)
            if rows:
                sub_dfs[f"{parent_name}_{col}"] = pd.DataFrame(rows)
            # Dejar como string en el main
            df[col] = df[col].astype(str)
    return df, sub_dfs


def save_to_excel(dfs, filename):
    os.makedirs(os.path.dirname(filename), exist_ok=True)
    with pd.ExcelWriter(filename, engine="openpyxl") as writer:
        for name, df in dfs.items():
            df.to_excel(writer, sheet_name=name[:31], index=False)
    print(f"✅ Archivo Excel generado con {dfs['Main'].shape[0]} registros en:\n{filename}")


def upload_to_google_sheets(dfs, sheet_id, creds_file):
    scope = ["https://spreadsheets.google.com/feeds",
             "https://www.googleapis.com/auth/drive"]
    creds = Credentials.from_service_account_file(creds_file, scopes=scope)
    client = gspread.authorize(creds)
    sheet = client.open_by_key(sheet_id)

    for name, df in dfs.items():
        sheet_name = name[:100]  # Sheets permite hasta 100 caracteres en el nombre
        try:
            worksheet = sheet.worksheet(sheet_name)
            sheet.del_worksheet(worksheet)
        except:
            pass
        worksheet = sheet.add_worksheet(title=sheet_name, rows=df.shape[0] + 1, cols=df.shape[1])
        worksheet.update([df.columns.values.tolist()] + df.values.tolist())
        print(f"📤 Hoja '{sheet_name}' actualizada en Google Sheets")


def main():
    # 1. Descargar datos de Kobo
    data = download_kobo_data(KOBO_URL)
    if not data:
        print("⚠️ No se encontraron registros en Kobo.")
        return

    # 2. Crear DataFrame principal
    df_main = pd.DataFrame(data)

    # 3. Separar columnas anidadas en sub-hojas
    df_main, sub_dfs = split_nested_data(df_main, "Main")
    dfs = {"Main": df_main}
    dfs.update(sub_dfs)

    # 4. Guardar en Excel
    save_to_excel(dfs, OUTPUT_FILE)

    # 5. Subir a Google Sheets
    upload_to_google_sheets(dfs, SHEET_ID, CREDENTIALS_FILE)


if __name__ == "__main__":
    main()
